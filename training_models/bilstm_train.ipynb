{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Vt7gO2zqkZoX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional,Input, Dropout, concatenate    \n",
    "from keras.models import Model \n",
    "#from tensorflow.keras.layers import Input\n",
    "#from keras_contrib.layers import CRF\n",
    "from tqdm import tqdm \n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "W8WiGzNlko10",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_excel('..\\data\\dataset4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZXx0eMs_lXnA"
   },
   "outputs": [],
   "source": [
    "data.Cumle.unique()\n",
    "\n",
    "df_len_cumle = pandas.DataFrame(data = {\"len_cumle\" : data.groupby(by=\"Cumle\").Kelime.count()})\n",
    "\n",
    "max_len_cumle = df_len_cumle.len_cumle.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f162z4yNlYp6"
   },
   "outputs": [],
   "source": [
    "tags = list(data['Etiket'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oPmgnpRflmVZ"
   },
   "outputs": [],
   "source": [
    "tag_to_index = {t : i  for i, t in enumerate(tags)}\n",
    "tag_to_index[\"PAD\"] = len(tag_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-PERSON': 0,\n",
       " 'I-PERSON': 1,\n",
       " 'O': 2,\n",
       " 'B-ORG': 3,\n",
       " 'I-ORG': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-LOC': 6,\n",
       " 'B-DATE': 7,\n",
       " 'I-DATE': 8,\n",
       " 'PAD': 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_tag = {i : t  for i, t in enumerate(tags)}\n",
    "index_to_tag[len(index_to_tag)] = \"PAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-PERSON',\n",
       " 1: 'I-PERSON',\n",
       " 2: 'O',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-DATE',\n",
       " 8: 'I-DATE',\n",
       " 9: 'PAD'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "17i2AOrxltIc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Convert label to index\\netiket_cumleler = [[tag_to_index[w[1]] for w in s] for s in sentences ]\\n\\n# padding\\netiket_cumleler = pad_sequences(maxlen = max_len_cumle, sequences = etiket_cumleler, padding = \"post\", value = tag_to_index[\"PAD\"])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Convert label to index\n",
    "etiket_cumleler = [[tag_to_index[w[1]] for w in s] for s in sentences ]\n",
    "\n",
    "# padding\n",
    "etiket_cumleler = pad_sequences(maxlen = max_len_cumle, sequences = etiket_cumleler, padding = \"post\", value = tag_to_index[\"PAD\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_11752\\3740747227.py:1: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  ft = FastText.load_fasttext_format(\"../data/cc.tr.300.bin\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.fasttext.FastText at 0x1a796d41820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = FastText.load_fasttext_format(\"../data/cc.tr.300.bin\")\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>[0.07097262, 0.004791385, -0.3005942, 0.062927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.</td>\n",
       "      <td>[0.08242141, 0.023221, 0.25061822, 0.023281153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'</td>\n",
       "      <td>[0.05154356, 0.045845818, -0.21159744, -0.1319...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>[0.07610206, -0.065875076, -0.5315242, 0.04710...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>[0.008432374, 0.008628698, 0.054383863, 0.0027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>:</td>\n",
       "      <td>[-0.03550936, 0.07336202, -0.01577426, 0.04979...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bir</td>\n",
       "      <td>[0.02556891, 0.029839218, 0.06793766, -0.04472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"</td>\n",
       "      <td>[-0.05937389, 0.18180937, 0.031832404, -0.0677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>)</td>\n",
       "      <td>[-0.18663986, -0.058338262, 0.12349557, 0.0335...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>’</td>\n",
       "      <td>[0.019061, -0.04711481, -0.19567162, -0.074336...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words                                            vectors\n",
       "0     ,  [0.07097262, 0.004791385, -0.3005942, 0.062927...\n",
       "1     .  [0.08242141, 0.023221, 0.25061822, 0.023281153...\n",
       "2     '  [0.05154356, 0.045845818, -0.21159744, -0.1319...\n",
       "3    ve  [0.07610206, -0.065875076, -0.5315242, 0.04710...\n",
       "4  </s>  [0.008432374, 0.008628698, 0.054383863, 0.0027...\n",
       "5     :  [-0.03550936, 0.07336202, -0.01577426, 0.04979...\n",
       "6   bir  [0.02556891, 0.029839218, 0.06793766, -0.04472...\n",
       "7     \"  [-0.05937389, 0.18180937, 0.031832404, -0.0677...\n",
       "8     )  [-0.18663986, -0.058338262, 0.12349557, 0.0335...\n",
       "9     ’  [0.019061, -0.04711481, -0.19567162, -0.074336..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "vectors = []\n",
    "words = []\n",
    "for index_nu in range(len(ft.wv.index_to_key)):\n",
    "    word = ft.wv.index_to_key[index_nu]\n",
    "    vectors.append(ft.wv[word])\n",
    "    words.append(word)\n",
    "    \n",
    "df_words_vectors = pandas.DataFrame({\"words\":words, \"vectors\":vectors})\n",
    "df_words_vectors[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim=300\n",
    "vector_padding = np.zeros(emb_dim)  \n",
    "vector_unfinded = np.random.uniform(-0.25, 0.25, emb_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_padding = {\"words\": \"PADDING\", \"vectors\":vector_padding}\n",
    "df_words_vectors.loc[2000000] = dict_padding\n",
    "\n",
    "dict_unfinded = {\"words\": \"UNFINDED\", \"vectors\":vector_unfinded}\n",
    "df_words_vectors.loc[2000001] = dict_unfinded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Etiket']=data[\"Etiket\"].apply(lambda x:tag_to_index[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pandas.DataFrame(columns=['word_vector','label_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kelime</th>\n",
       "      <th>Etiket</th>\n",
       "      <th>Cumle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>saldırısı</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>sonunda</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>Abdurrahmanın</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>elinde</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>yalnızca</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>Septe</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>ile</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>Tanca</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>kaldı</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>Blur</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>İngiliz</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Kelime  Etiket  Cumle\n",
       "1150      saldırısı       2     85\n",
       "1151        sonunda       2     85\n",
       "1152  Abdurrahmanın       0     85\n",
       "1153         elinde       2     85\n",
       "1154       yalnızca       2     85\n",
       "1155          Septe       0     85\n",
       "1156            ile       2     85\n",
       "1157          Tanca       0     85\n",
       "1158          kaldı       2     85\n",
       "1159           Blur       3     86\n",
       "1160        İngiliz       2     86"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1150:1160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vector</th>\n",
       "      <th>label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>[Eylül, 2010da, iki, single, yayımladı, The, B...</td>\n",
       "      <td>[7, 8, 2, 2, 2, 3, 4, 4, 4, 2, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>[Batman, Çine, gidip, Louyu, Gothama, getirir]</td>\n",
       "      <td>[0, 5, 2, 0, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>[2008, Cup, of, China, Cup, of, China, Grand, ...</td>\n",
       "      <td>[7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 8, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>[1980, NBA, All, Star, Maçı, 4, Şubat, 1980, t...</td>\n",
       "      <td>[2, 3, 4, 4, 4, 7, 8, 8, 2, 5, 6, 2, 5, 6, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>[2010, 11, Sezonunu, bitimine, Chelsea, 50, mi...</td>\n",
       "      <td>[7, 2, 2, 2, 3, 2, 2, 2, 0, 2, 2, 2, 0, 3, 4, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            word_vector   \n",
       "1860  [Eylül, 2010da, iki, single, yayımladı, The, B...  \\\n",
       "789      [Batman, Çine, gidip, Louyu, Gothama, getirir]   \n",
       "1089  [2008, Cup, of, China, Cup, of, China, Grand, ...   \n",
       "391   [1980, NBA, All, Star, Maçı, 4, Şubat, 1980, t...   \n",
       "245   [2010, 11, Sezonunu, bitimine, Chelsea, 50, mi...   \n",
       "\n",
       "                                           label_vector  \n",
       "1860                  [7, 8, 2, 2, 2, 3, 4, 4, 4, 2, 0]  \n",
       "789                                  [0, 5, 2, 0, 5, 2]  \n",
       "1089      [7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 8, 2, 2, 2]  \n",
       "391   [2, 3, 4, 4, 4, 7, 8, 8, 2, 5, 6, 2, 5, 6, 2, ...  \n",
       "245   [7, 2, 2, 2, 3, 2, 2, 2, 0, 2, 2, 2, 0, 3, 4, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cumle_no in range (len(data.Cumle.unique())-1):\n",
    "    a= data.groupby(\"Cumle\", group_keys = True).apply(lambda s:s).loc[cumle_no][\"Kelime\"].values.tolist() \n",
    "    b= data.groupby(\"Cumle\", group_keys = True).apply(lambda s:s).loc[cumle_no][\"Etiket\"].values.tolist() \n",
    "    dataset.loc[cumle_no] = {\"word_vector\": a, \"label_vector\": b}\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_to_index = df_words_vectors[\"words\"]\n",
    "word_to_index = word_to_index.tolist()\n",
    "\"\"\"\n",
    "veri setimizdeki sıralmayla veri setindeki kelimerlin fastText karşılıklarını alduğın yapı\n",
    "(o yapı \"word_indices\")\n",
    "\"\"\"\n",
    "\n",
    "cumleler_indices=[]\n",
    "word_indices = []\n",
    "\n",
    "#cumlelerdeki kelimelerin indeks numaralarını cumle icindeki haliyle sıralanmasi\n",
    "for cumle in dataset.word_vector:\n",
    "    word_indices = []\n",
    "    for word in cumle:\n",
    "\n",
    "        if str(word) in word_to_index:\n",
    "            word_idx = word_to_index.index(str(word))\n",
    "        elif str(word).lower() in word_to_index:\n",
    "            word_idx = word_to_index.index(str(word).lower())\n",
    "        else:\n",
    "            word_idx = word_to_index.index(\"UNFINDED\")\n",
    "        word_indices.append(word_idx)\n",
    "    cumleler_indices.append(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 552855,  117294,       6, ..., 2000000, 2000000, 2000000],\n",
       "       [ 117294,   11450,    8375, ..., 2000000, 2000000, 2000000],\n",
       "       [ 505477,     801,    9176, ..., 2000000, 2000000, 2000000],\n",
       "       ...,\n",
       "       [   5738,     319,   76905, ..., 2000000, 2000000, 2000000],\n",
       "       [  57123,      26,   34768, ..., 2000000, 2000000, 2000000],\n",
       "       [  21088,     385,     100, ..., 2000000, 2000000, 2000000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_cumleler = pad_sequences(maxlen = max_len_cumle, sequences = cumleler_indices, padding = \"post\", value = df_words_vectors[df_words_vectors[\"words\"] == \"PADDING\"].index[0] )    \n",
    "embedding_cumleler[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 43)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_cumleler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen = max_len_cumle, sequences = dataset.label_vector, padding = \"post\", value = tag_to_index[\"PAD\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    list_sentence = dataset.word_vector.loc[i]\n",
    "    times_pad=44-len( dataset.word_vector.loc[i])                       \n",
    "    for j in range(times_pad):\n",
    "        list_sentence.append(vector_padding)\n",
    "    dataset.word_vector.loc[i] = list_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = embedding_cumleler[:414]\n",
    "y_test = y[:414]\n",
    "\n",
    "X_train = embedding_cumleler[414:]\n",
    "y_train = y[414:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 43)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = np.vstack(df_words_vectors[\"vectors\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "compressed_vectors = pca.fit_transform(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000002, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class CRFLayer(Layer):\n",
    "    def __init__(self, num_tags, **kwargs):\n",
    "        super(CRFLayer, self).__init__(**kwargs)\n",
    "        self.num_tags = num_tags\n",
    "        self.transition_params = self.add_weight(\n",
    "            name='transitions',\n",
    "            shape=(self.num_tags, self.num_tags),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        sequence_lengths = tf.reduce_sum(tf.cast(tf.sequence_mask(tf.reduce_sum(tf.cast(tf.math.not_equal(inputs, 0), tf.int32), axis=1)), tf.int32), axis=1)\n",
    "        viterbi_sequence, _ = tfa.text.crf_decode(inputs, self.transition_params, sequence_lengths)\n",
    "        output = tf.one_hot(viterbi_sequence, self.num_tags)\n",
    "        return output\n",
    "\n",
    "    def loss(self, y_true, y_pred):\n",
    "        sequence_lengths = tf.reduce_sum(tf.cast(tf.sequence_mask(tf.reduce_sum(tf.cast(tf.math.not_equal(y_true, 0), tf.int32), axis=1)), tf.int32), axis=1)\n",
    "        log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(y_pred, tf.argmax(y_true, axis=-1), sequence_lengths, self.transition_params)\n",
    "        return -log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "723WYAU--4Pt",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# model Mimarisi\n",
    "# word-level (embedding_cumleler) input\n",
    "kelimeler_in = Input(shape=(None,), dtype='float64', name='words_input')\n",
    "words = Embedding(input_dim = 2000002, output_dim = 100, \n",
    "                  weights=[compressed_vectors], trainable = False)(kelimeler_in)\n",
    "\n",
    "\n",
    "# concat all input layers & pass it through BiLSTM layer\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, \n",
    "                            dropout = 0.5,\n",
    "                            recurrent_dropout=0.25\n",
    "                           ), name=\"BiLSTM_layer\")(words)\n",
    "\n",
    "output = TimeDistributed(Dense(len(tag_to_index), activation='softmax'), name=\"softmax_layer\")(x)\n",
    "#crf = CRFLayer(len(tag_to_index))  # CRF layer\n",
    "#out = crf(output)\n",
    "\n",
    "\n",
    "# Build and compile the model\n",
    "model = Model(inputs=[kelimeler_in], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " words_input (InputLayer)    [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         200000200 \n",
      "                                                                 \n",
      " BiLSTM_layer (Bidirectional  (None, None, 128)        84480     \n",
      " )                                                               \n",
      "                                                                 \n",
      " softmax_layer (TimeDistribu  (None, None, 12)         1548      \n",
      " ted)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,086,228\n",
      "Trainable params: 86,028\n",
      "Non-trainable params: 200,000,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = Nadam())\n",
    "#model.compile(optimizer='adam', loss=tfa.losses.crf_loss)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1652/1652 [==============================] - 473s 283ms/step - loss: 0.3353\n",
      "Epoch 2/7\n",
      "1652/1652 [==============================] - 499s 302ms/step - loss: 0.1815\n",
      "Epoch 3/7\n",
      "1652/1652 [==============================] - 493s 299ms/step - loss: 0.1498\n",
      "Epoch 4/7\n",
      "1652/1652 [==============================] - 384s 232ms/step - loss: 0.1352\n",
      "Epoch 5/7\n",
      "1652/1652 [==============================] - 410s 248ms/step - loss: 0.1233\n",
      "Epoch 6/7\n",
      "1652/1652 [==============================] - 419s 254ms/step - loss: 0.1149\n",
      "Epoch 7/7\n",
      "1652/1652 [==============================] - 371s 224ms/step - loss: 0.1089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1f357cb50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x= X_train, y=y_train, batch_size=1, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/bilstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model = models.load_model('../models/bilstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(word):\n",
    "    try:\n",
    "        return df_words_vectors[df_words_vectors.words == word].index.values[0]\n",
    "    except IndexError:\n",
    "        return 2000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2373,   14563,   24518,   80449,   48902,       1, 2000000,\n",
       "        2000000, 2000000, 2000000, 2000000, 2000000, 2000000, 2000000,\n",
       "        2000000, 2000000, 2000000, 2000000, 2000000, 2000000, 2000000,\n",
       "        2000000, 2000000, 2000000, 2000000, 2000000, 2000000, 2000000,\n",
       "        2000000, 2000000, 2000000, 2000000, 2000000, 2000000, 2000000,\n",
       "        2000000, 2000000, 2000000, 2000000, 2000000, 2000000, 2000000,\n",
       "        2000000]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_sentence = [\"5\", \"Ekim\",\"Bülent\", \"Ecevit\", \"Üniversitesine\", \"gidilecek\"]\n",
    "#test_sentence = [\"Mustafa\", \"Kemal\",\"Atatürk\", \"19\", \"Mayıs\", \"1919'da\",\"Samsun'a\",\"çıktı\"]\n",
    "\n",
    "#test_sentence = [\"Rusya\", \"devleti\", \"savaşta\", \"tarafsız\", \"kaldı\",\".\"]\n",
    "test_sentence = [\"Metin\", \"Bilgin\", \"hocanın\", \"danışmanlığında\", \"katıldık\",\".\"]\n",
    "\n",
    "\n",
    "test_input = pad_sequences([[get_index(word) for word in test_sentence]], maxlen=max_len_cumle, padding=\"post\", value = get_index(\"PADDING\") )   \n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "['Metin', 'Bilgin', 'hocanın', 'danışmanlığında', 'katıldık', '.']\n",
      "['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# tek bir cumle icin VİT tahmini\n",
    "predictions = model.predict(test_input)\n",
    "predicted_tags = [list(tag_to_index)[idx] for idx in np.argmax(predictions, axis=-1)[0]]\n",
    "\n",
    "print(test_sentence)\n",
    "print(predicted_tags[:len(test_sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(414, 1, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 756ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 841ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 839ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 744ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "1/1 [==============================] - 1s 871ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 828ms/step\n",
      "1/1 [==============================] - 1s 910ms/step\n",
      "1/1 [==============================] - 1s 765ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_list = []\n",
    "for i in range(len(X_test)):\n",
    "    predictions = model.predict(X_test[i])\n",
    "    predicted_tags = [idx for idx in np.argmax(predictions, axis=-1)[0]]\n",
    "    predicted_list.append(predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(predicted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 43)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test.reshape(17802,1), preds.reshape(17802,1),average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " B-PERSON: F1 score: 0.6541737649063032\n",
      " I-PERSON: F1 score: 0.7478260869565216\n",
      " O: F1 score: 0.9300052826201796\n",
      " B-ORG: F1 score: 0.4968553459119498\n",
      " I-ORG: F1 score: 0.4882352941176471\n",
      " B-LOC: F1 score: 0.7330779054916985\n",
      " I-LOC: F1 score: 0.4423963133640553\n",
      " B-DATE: F1 score: 0.8423913043478262\n",
      " I-DATE: F1 score: 0.7781155015197568\n",
      " I-TIME: F1 score: 0.0\n",
      " B-TIME: F1 score: 0.14285714285714288\n",
      " PAD: F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "for class_id, f1_ in enumerate(f1):\n",
    "    print(\" {}: F1 score: {}\".format(index_to_tag[class_id], f1_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.append(\"PAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-PERSON       0.57      0.77      0.65       249\n",
      "    I-PERSON       0.70      0.80      0.75       162\n",
      "           O       0.92      0.94      0.93      3741\n",
      "       B-ORG       0.73      0.38      0.50       210\n",
      "       I-ORG       0.72      0.37      0.49       224\n",
      "       B-LOC       0.66      0.82      0.73       350\n",
      "       I-LOC       0.53      0.38      0.44       127\n",
      "      B-DATE       0.88      0.81      0.84       191\n",
      "      I-DATE       0.79      0.77      0.78       166\n",
      "      I-TIME       0.00      0.00      0.00        13\n",
      "      B-TIME       0.33      0.09      0.14        11\n",
      "         PAD       1.00      1.00      1.00     12358\n",
      "\n",
      "    accuracy                           0.95     17802\n",
      "   macro avg       0.65      0.59      0.60     17802\n",
      "weighted avg       0.95      0.95      0.95     17802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.reshape(17802,1), preds.reshape(17802,1), target_names=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f1 = f1_score(y_test.reshape(17802,1), preds.reshape(17802,1),average=None)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(tags, f1.tolist())\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Scores for Each Class')\n",
    "plt.xticks(tags)\n",
    "plt.ylim(0, 1)  # Optional: Set the y-axis limits\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
